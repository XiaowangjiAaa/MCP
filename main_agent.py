import os
import json
from openai import OpenAI
from dotenv import load_dotenv
from agent.executor import execute_plan
from tools.path_utils import get_test_image_paths, get_test_image_by_index
from MCP.visualize_tools import visualize_crack_result
from agent.gpt_intent_parser import generate_composite_plan
from agent.object_memory_manager import ObjectMemoryManager
from agent.session_manager import SessionManager



load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

session = SessionManager()
logger = session.get_logger()
memory = session.get_memory()
object_store = ObjectMemoryManager()

DEFAULT_METRICS = ["max_width", "avg_width", "length", "area"]


def generate_agent_reply(user_input: str, plan: dict, results: list) -> str:
    rag_result = next((r for r in results if r.get("tool") == "rag_answer" and r.get("status") == "success"), None)
    if rag_result:
        return rag_result["outputs"].get("answer", "")

    prompt = (
        "ä½ æ˜¯ä¸€ä¸ªä¸“æ³¨äºè£‚ç¼å›¾åƒåˆ†æçš„ AI åŠ©æ‰‹\n"
        "è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯ï¼Œç”¨è‡ªç„¶è¯­è¨€æ€»ç»“ä»»åŠ¡å®Œæˆæƒ…å†µ\n"
        "è¦æ±‚è¯­è¨€ç®€æ´æ¸…æ™°ï¼Œå°½å¯èƒ½æåŠå›¾åƒç¼–å·ã€å¤„ç†å†…å®¹å’Œå…³é”®ç»“æœï¼š\n\n"
        f"ğŸ–ï¸ ç”¨æˆ·è¯·æ±‚ï¼š{user_input}\n"
        f"ğŸ“‹ æ‰§è¡Œè®¡åˆ’ï¼š{json.dumps(plan, ensure_ascii=False)}\n"
        f"âœ… æ‰§è¡Œç»“æœï¼š{json.dumps(results, ensure_ascii=False)}\n\n"
        "è¯·ç›´æ¥ç”Ÿæˆä¸€æ®µå›å¤ï¼Œä¸è¦é™„åŠ è§£é‡Šæˆ–æ ¼å¼æ ‡ç­¾ã€‚"
    )
    response = client.chat.completions.create(
        model="gpt-4.1-mini",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šè£‚ç¼å›¾åƒåˆ†æ AIï¼Œè´Ÿè´£ç”Ÿæˆè‡ªç„¶è¯­è¨€åˆ†æç­”å¤ã€‚"},
            {"role": "user", "content": prompt}
        ]
    )
    return response.choices[0].message.content.strip()


def chat_fallback(user_input: str) -> str:
    response = client.chat.completions.create(
        model="gpt-4.1-mini",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“æ³¨äºè£‚ç¼å›¾åƒåˆ†æçš„ AI Agentã€‚"},
            {"role": "user", "content": user_input}
        ]
    )
    reply = response.choices[0].message.content.strip()
    logger.log_agent(reply)
    return reply


def normalize(s: str) -> str:
    return s.lower().replace(" ", "").replace("_", "").replace("(", "").replace(")", "")


def match_metric_key(requested: str, candidate: str) -> bool:
    return normalize(requested) in normalize(candidate)


if __name__ == "__main__":
    while True:
        user_input = input("\nğŸ§  è¯·è¾“å…¥è‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼ˆæˆ– exitï¼‰: ")
        if user_input.strip().lower() in {"exit", "quit"}:
            session.export_memory_snapshot()
            session.print_summary()
            break

        logger.log_user(user_input)
        print("ğŸ—½ æ­£åœ¨ç†è§£æ„å›¾...")

        plan = generate_composite_plan(user_input)
        steps = plan.get("steps", [])

        if all(step["action"] == "chat" for step in steps):
            has_rag_tool = any(step.get("tool", "").lower() == "rag_answer" for step in steps)
            
            if has_rag_tool:
                print("ğŸ“š è§¦å‘çŸ¥è¯†é—®ç­” rag_answer å·¥å…·æ‰§è¡Œ...")
                tool_plan = steps  # âœ… ç›´æ¥å°† planner ç”Ÿæˆçš„ steps ä½œä¸ºæ‰§è¡Œè®¡åˆ’
                results = execute_plan(tool_plan, memory=memory)
                reply = generate_agent_reply(user_input, plan, results)
                print("\nğŸ’¬ AI å›ç­”:")
                print(reply)
                logger.log_agent(reply)
                continue
            
            else:
                print("ğŸ’¬", chat_fallback(user_input))
                continue

        print("\nğŸ“‹ ä»»åŠ¡è®¡åˆ’:")
        for i, step in enumerate(steps):
            print(f"{i+1}. {step['action']} â†’ index={step.get('target_indices')}")

        tool_plan = []
        results = []
        all_images = get_test_image_paths()
        index_to_image_name = {
            i: os.path.basename(p).replace(".jpg", "").replace(".png", "").replace(".jpeg", "")
            for i, p in enumerate(all_images)
        }

        for step in steps:
            action = step["action"]
            indices = step.get("target_indices", [])

            if isinstance(indices, list) and "all" in indices:
                indices = list(range(len(all_images)))
            elif isinstance(indices, str) and indices == "all":
                indices = list(range(len(all_images)))

            step["target_indices"] = indices
            pixel_size = step.get("pixel_size_mm", 0.5)
            metrics = step.get("metrics", [])
            visual_types = step.get("visual_types", [])

            if action == "quantify" and not metrics:
                metrics = DEFAULT_METRICS
                step["metrics"] = metrics
            if action == "visualize" and not visual_types:
                visual_types = ["original", "mask"]
                step["visual_types"] = visual_types

            if not indices:
                print(f"âš ï¸ æ­¥éª¤ [{action}] ç¼ºå°‘å›¾åƒç´¢å¼•")
                continue

            for i in indices:
                img_path = get_test_image_by_index(i)
                name = index_to_image_name[i]
                object_store.register_image(img_path)
                mask_name = os.path.basename(img_path).replace(".jpg", ".png").replace(".jpeg", ".png")
                mask_path = os.path.join("outputs/masks", mask_name)

                if action == "segment":
                    if os.path.exists(mask_path):
                        print(f"â™»ï¸ æ©è†œå·²å­˜åœ¨ï¼Œè·³è¿‡ segment: {mask_path}")
                        results.append({
                            "tool": "segment_crack_image",
                            "status": "success",
                            "summary": "æ©è†œå·²å­˜åœ¨äºç£ç›˜ï¼Œè·³è¿‡æ‰§è¡Œ",
                            "outputs": {"mask_path": mask_path},
                            "visualizations": None,
                            "args": {"image_path": img_path},
                            "subject": name
                        })
                        continue
                    tool_plan.append({
                        "tool": "segment_crack_image",
                        "args": {"image_path": img_path},
                        "subject": name
                    })

                elif action == "quantify":
                    if memory.has_metrics(name, metrics, pixel_size):
                        print(f"âœ… å›¾åƒ {name} çš„æŒ‡æ ‡å·²å­˜åœ¨äº memoryï¼Œä½¿ç”¨ç¼“å­˜ç»“æœã€‚")
                        metric_values = memory.get_metrics_by_name(name, pixel_size)
                        outputs = {k: v for k, v in metric_values.items() if any(map(lambda m: m.lower() in k.lower(), metrics))}
                        results.append({
                            "tool": "quantify_crack_geometry",
                            "status": "success",
                            "summary": f"è¯»å–è‡ª memoryï¼ŒåŒ…å« {len(outputs)} é¡¹æŒ‡æ ‡",
                            "outputs": outputs,
                            "visualizations": None,
                            "args": {
                                "mask_path": mask_path,
                                "pixel_size_mm": pixel_size,
                                "metrics": metrics,
                                "visuals": []
                            },
                            "subject": name
                        })
                        continue

                    args = {
                        "mask_path": mask_path,
                        "pixel_size_mm": pixel_size,
                        "metrics": metrics
                    }
                    if "visual_types" in step:
                        args["visuals"] = step["visual_types"]

                    tool_plan.append({
                        "tool": "quantify_crack_geometry",
                        "args": args,
                        "subject": name
                    })

                elif action == "generate":
                    args = {
                        "mask_path": mask_path,
                        "pixel_size_mm": pixel_size,
                        "metrics": [],
                        "visuals": visual_types
                    }
                    tool_plan.append({
                        "tool": "quantify_crack_geometry",
                        "args": args,
                        "subject": name
                    })

                elif action == "visualize":
                    vis_paths = visualize_crack_result(subject_name=name, memory=memory, visual_types=visual_types)
                    results.append({
                        "tool": "visualize_crack_result",
                        "status": "success" if vis_paths else "no_output",
                        "summary": f"ç”Ÿæˆäº† {len(vis_paths)} å¼ å¯è§†åŒ–å›¾" if vis_paths else "æœªç”Ÿæˆå¯è§†åŒ–å›¾åƒ",
                        "outputs": {},
                        "visualizations": vis_paths,
                        "args": {"subject_name": name, "visual_types": visual_types},
                        "subject": name
                    })

        if not tool_plan and results:
            print("â™»ï¸ æ‰€æœ‰æ­¥éª¤å·²ç”± memory å‘½ä¸­ï¼Œæ— éœ€æ‰§è¡Œå·¥å…·é“¾ã€‚")
        else:
            print("\nğŸš€ æ­£åœ¨æ‰§è¡Œ:")
            for step in tool_plan:
                print(f"â†’ {step['tool']}({step['args']})")
            exec_results = execute_plan(tool_plan, memory=memory)
            results += exec_results

            # âœ… æ–°å¢ï¼šä¿å­˜ generate å¯è§†åŒ–å›¾åˆ° memory
            for r in exec_results:
                if r['tool'] == "quantify_crack_geometry" and r['status'] == "success":
                    subject = r["subject"]
                    visual_paths = r.get("visualizations", {})
                    if visual_paths:
                        memory.save_visualizations(subject, pixel_size, visual_paths)

        for r in results:
            print(f"[{r['tool']}] â†’ {r['status']}")
            if r['tool'] == "quantify_crack_geometry" and r['status'] == "success":
                print("ğŸ“Š è¯·æ±‚æŒ‡æ ‡:")
                for k, v in r.get("outputs", {}).items():
                    print(f"  {k}: {v}")

        for step in tool_plan:
            if "action" not in step:
                step["action"] = step.get("task", "")  # âœ… å…¼å®¹ memory é€»è¾‘

        memory.update_context(
            intent="multi_step",
            indices=[i for step in steps for i in step.get("target_indices", [])],
            pixel_size=pixel_size,
            results=results,
            plan=tool_plan
        )

        logger.log_agent_structured({
            "intent": "multi_step",
            "user_input": user_input,
            "steps": steps,
            "tool_plan": tool_plan,
            "result": results,
            "message": "âœ… å¤šæ­¥éª¤ä»»åŠ¡å®Œæˆ"
        })

        reply = generate_agent_reply(user_input, tool_plan, results)
        print("\nğŸ’¬ AI æ€»ç»“ç­”å¤:")
        print(reply)
        logger.log_agent(reply)
