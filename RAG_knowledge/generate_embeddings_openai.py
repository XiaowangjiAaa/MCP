from openai import OpenAI
import json
import time
import os
from dotenv import load_dotenv

# âœ… åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


# âœ… æ–‡ä»¶è·¯å¾„
INPUT_PATH = r"E:\UTS_work_code\Agentic_AI\Agentic_AI_MCP_1\RAG_knowledge\regulations_data\USA_crack_control_chunks_translated_en.json"
OUTPUT_PATH = r"E:\UTS_work_code\Agentic_AI\Agentic_AI_MCP_1\RAG_knowledge\regulations_embeddings\USA_crack_control_chunks_with_dual_embeddings.json"
ERROR_LOG_PATH = r"E:\UTS_work_code\Agentic_AI\Agentic_AI_MCP\RAG\embedding_dual_errors.json"

# âœ… åŠ è½½ä¸­è‹±ç»“æ„åŒ–æ–‡æœ¬
with open(INPUT_PATH, "r", encoding="utf-8") as f:
    chunks = json.load(f)

embedded_chunks = []
error_chunks = []

for idx, chunk in enumerate(chunks):
    try:
        # ä¸­æ–‡å‘é‡
        embedding_zh = client.embeddings.create(
            model="text-embedding-3-large",
            input=chunk["text_zh"]
        ).data[0].embedding
        chunk["embedding_zh"] = embedding_zh

        # è‹±æ–‡å‘é‡
        embedding_en = client.embeddings.create(
            model="text-embedding-3-large",
            input=chunk["text_en"]
        ).data[0].embedding
        chunk["embedding_en"] = embedding_en

        embedded_chunks.append(chunk)
        print(f"[{idx+1}/{len(chunks)}] âœ… Embedded (ZH + EN)")
        time.sleep(1)

    except Exception as e:
        print(f"[{idx+1}] âŒ Error embedding chunk: {e}")
        chunk["error"] = str(e)
        error_chunks.append(chunk)
        continue

# âœ… ä¿å­˜å«ä¸­è‹± embedding çš„å®Œæ•´æ•°æ®
with open(OUTPUT_PATH, "w", encoding="utf-8") as f:
    json.dump(embedded_chunks, f, ensure_ascii=False, indent=2)

# âœ… ä¿å­˜é”™è¯¯æ—¥å¿—
if error_chunks:
    with open(ERROR_LOG_PATH, "w", encoding="utf-8") as f:
        json.dump(error_chunks, f, ensure_ascii=False, indent=2)
    print(f"\nâš ï¸ {len(error_chunks)} chunks failed. See {ERROR_LOG_PATH}")

print(f"\nğŸ‰ All done! {len(embedded_chunks)} chunks with dual embeddings saved to:\n{OUTPUT_PATH}")
